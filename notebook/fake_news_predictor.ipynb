{
  "metadata": {
    "name": "fake_news_predictor",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.sql.types._\nimport org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\nimport org.apache.spark.ml.classification._\nimport org.apache.spark.ml.{Pipeline, PipelineModel}\nimport org.apache.spark.ml.tuning.{CrossValidator, ParamGridBuilder}\nimport org.apache.spark.ml.feature.{HashingTF, IDF, Tokenizer}\nimport org.apache.spark.ml.Model\nimport org.apache.spark.sql._"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "def readCsv(path: String) \u003d spark.read\n    .option(\"header\", true)\n    .option(\"quote\", \"\\\"\")\n    .option(\"delimiter\", \",\")\n    .option(\"charset\", \"utf-8\")\n    .option(\"escape\",\"\\\"\")\n    .option(\"multiline\",true)\n    .csv(path)\n\ndef getShape(dataset: DataFrame) \u003d (dataset.count(), dataset.columns.length)\n\ndef isNullOrEmpty(column:Column): Column \u003d {\n    column.isNull or column \u003c\u003d\u003e lit(\"\") or column.isNaN or column \u003c\u003d\u003e lit(\"nan\")\n}"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val submitDataPath \u003d \"/data/submit.csv\"\nval testDataPath \u003d \"/data/test.csv\"\nval trainDataPath \u003d \"/data/train.csv\"\nval submitData \u003d readCsv(submitDataPath) \nval testData \u003d readCsv(testDataPath) \nval trainData \u003d readCsv(trainDataPath)"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "trainData.show(10)\ntestData.show(10)\nsubmitData.show(10)\nprintln(s\"Train Shape : ${getShape(trainData)}\")\nprintln(s\"Test Shape : ${getShape(testData)}\")\nprintln(s\"Submit Shape : ${getShape(submitData)}\")"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "println(\"Train data summary\")\nprintln(\"Schema\")\ntrainData.printSchema()\nprintln(\"Summary (all)\")\ntrainData.summary(\"count\").show()\nprintln(\"Summary (not nulls)\")\nprintln(s\"\"\"id - ${trainData.select(\"id\").filter(!isNullOrEmpty($\"id\")).count()}\"\"\")\nprintln(s\"\"\"title - ${trainData.select(\"title\").filter(!isNullOrEmpty($\"title\")).count()}\"\"\")\nprintln(s\"\"\"author - ${trainData.select(\"author\").filter(!isNullOrEmpty($\"author\")).count()}\"\"\")\nprintln(s\"\"\"text - ${trainData.select(\"text\").filter(!isNullOrEmpty($\"text\")).count()}\"\"\")\nprintln(s\"\"\"label - ${trainData.select(\"label\").filter(!isNullOrEmpty($\"label\")).count()}\"\"\")\nprintln(\"Summary (nulls)\")\nprintln(s\"\"\"id - ${trainData.select(\"id\").filter(isNullOrEmpty($\"id\")).count()}\"\"\")\nprintln(s\"\"\"title - ${trainData.select(\"title\").filter(isNullOrEmpty($\"title\")).count()}\"\"\")\nprintln(s\"\"\"author - ${trainData.select(\"author\").filter(isNullOrEmpty($\"author\")).count()}\"\"\")\nprintln(s\"\"\"text - ${trainData.select(\"text\").filter(isNullOrEmpty($\"text\")).count()}\"\"\")\nprintln(s\"\"\"label - ${trainData.select(\"label\").filter(isNullOrEmpty($\"label\")).count()}\"\"\")"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val joinedTestData \u003d testData\n    .join(submitData.withColumnRenamed(\"id\", \"id2\"), $\"id\" \u003d\u003d\u003d $\"id2\", \"inner\")\n    .drop(\"id2\")\n\nval filledTrainData \u003d trainData\n    .withColumn(\"title\", when(isNullOrEmpty($\"title\"), \"\").otherwise($\"title\"))\n    .withColumn(\"author\", when(isNullOrEmpty($\"author\"), \"\").otherwise($\"author\"))\n    .withColumn(\"text\", when(isNullOrEmpty($\"text\"), \"\").otherwise($\"text\"))\n    \nval filledTestData \u003d joinedTestData\n    .withColumn(\"title\", when(isNullOrEmpty($\"title\"), \"\").otherwise($\"title\"))\n    .withColumn(\"author\", when(isNullOrEmpty($\"author\"), \"\").otherwise($\"author\"))\n    .withColumn(\"text\", when(isNullOrEmpty($\"text\"), \"\").otherwise($\"text\"))\n    \nval trainDataWithTotal \u003d filledTrainData\n    .withColumn(\"total\", concat_ws(\" \", $\"title\", $\"author\", $\"text\"))\n\nval testDataWithTotal \u003d filledTestData\n    .withColumn(\"total\", concat_ws(\" \", $\"title\", $\"author\", $\"text\"))\n    \nval trainingData \u003d trainDataWithTotal\n    .select(\"label\", \"total\")\n    .withColumn(\"label\", col(\"label\").cast(\"int\"))\n    \nval testingData \u003d testDataWithTotal\n    .select(\"label\", \"total\")\n    .withColumn(\"label\", col(\"label\").cast(\"int\"))"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "trainingData.show(10)\ntestingData.show(10)"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val tokenizer \u003d new Tokenizer().setInputCol(\"total\").setOutputCol(\"words\")\nval hashingTF \u003d new HashingTF().setInputCol(\"words\").setOutputCol(\"rawFeatures\").setNumFeatures(30)\nval idf \u003d new IDF().setInputCol(\"rawFeatures\").setOutputCol(\"features\").setMinDocFreq(5)\n\nval pipeline \u003d new Pipeline().setStages(Array(tokenizer, hashingTF, idf))"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val model \u003d pipeline.fit(trainingData)\nval transformedTrainingData \u003d model.transform(trainingData)\nval transformedTestingData \u003d model.transform(testingData)"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "transformedTrainingData.show(10)"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "def logisticRegressionModelLearning(trainData: DataFrame, testData: DataFrame) \u003d {\n    val classifier \u003d new LogisticRegression()\n        .setLabelCol(\"label\")\n        .setFeaturesCol(\"features\")\n        .setAggregationDepth(2)\n        .setThreshold(0.5)\n        .setFamily(\"auto\")\n        .setStandardization(true)\n        .setFitIntercept(true)\n        .setMaxIter(100)\n        .setTol(1E-6)\n        .setRegParam(0.0)\n        .setElasticNetParam(0.0)\n    val model \u003d classifier.fit(trainData)\n    val predictions \u003d model.transform(testData)\n    val evaluator \u003d new BinaryClassificationEvaluator().setLabelCol(\"label\")\n    val accuracy \u003d evaluator.evaluate(predictions)\n    println(s\"Model accuracy: ${accuracy}\")\n}\nlogisticRegressionModelLearning(transformedTrainingData, transformedTestingData)"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "def randomForestModelLearning(trainData: DataFrame, testData: DataFrame) \u003d {\n    val classifier \u003d new RandomForestClassifier()\n        .setLabelCol(\"label\")\n        .setFeaturesCol(\"features\")\n    val model \u003d classifier.fit(trainData)\n    val predictions \u003d model.transform(testData)\n    val evaluator \u003d new BinaryClassificationEvaluator().setLabelCol(\"label\")\n    val accuracy \u003d evaluator.evaluate(predictions)\n    println(s\"Model accuracy: ${accuracy}\")\n}\nrandomForestModelLearning(transformedTrainingData, transformedTestingData)"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "def svmModelLearning(trainData: DataFrame, testData: DataFrame) \u003d {\n    val classifier \u003d new LinearSVC()\n        .setLabelCol(\"label\")\n        .setFeaturesCol(\"features\")\n        .setAggregationDepth(2)\n        .setStandardization(true)\n        .setTol(1E-6)\n        .setFitIntercept(true)\n        .setMaxIter(100)\n        .setRegParam(0.0)\n    val model \u003d classifier.fit(trainData)\n    val predictions \u003d model.transform(testData)\n    val evaluator \u003d new BinaryClassificationEvaluator().setLabelCol(\"label\")\n    val accuracy \u003d evaluator.evaluate(predictions)\n    println(s\"Model accuracy: ${accuracy}\")\n}\nsvmModelLearning(transformedTrainingData, transformedTestingData)"
    }
  ]
}